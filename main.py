import os
import time
import requests
import json
import feedparser
import urllib.parse
import smtplib
import logging
from datetime import datetime, timedelta, timezone
from google import genai
from collections import defaultdict
from urllib.parse import urlparse
from dateutil import parser as date_parser
from googlenewsdecoder import gnewsdecoder
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# =========================================================
# 0. ë¡œê¹… ì„¤ì •
# =========================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
log = logging.getLogger(__name__)

# =========================================================
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# =========================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
KAKAO_REFRESH_TOKEN = os.getenv("KAKAO_REFRESH_TOKEN")
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY")
KAKAO_CLIENT_SECRET = os.getenv("KAKAO_CLIENT_SECRET")
GMAIL_USER = os.getenv("GMAIL_USER")
GMAIL_APP_PASSWORD = os.getenv("GMAIL_APP_PASSWORD")

client = genai.Client(api_key=GEMINI_API_KEY)

# Gemini ëª¨ë¸ ìš°ì„ ìˆœìœ„ (ê³µí†µ ìƒìˆ˜í™”)
GEMINI_MODELS = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"]

KEYWORDS = [
    'semiconductor', 'advanced packaging', 'hbm', 'tsmc', 'samsung', 'sk hynix',
    'wafer', 'chiplet', 'interposer', 'Hybrid Bonding', 'CoWoS', 'FOWLP', 'intel',
    'Glass Substrate', 'TC-NCF', 'MUF', 'EMC', 'CXL', 'BSPDN', 'Silicon Photonics',
    'Logic Semiconductor', 'Foundry', 'Automotive Chip', 'NVIDIA', 'AMD'
]

GLOBAL_TARGETS = {
    "semiengineering.com": "Semiconductor Engineering",
    "3dincites.com": "3D InCites",
    "digitimes.com": "Digitimes",
    "eetimes.com": "EE Times",
    "trendforce.com": "TrendForce",
    "semiconductor-digest.com": "Semi Digest",
    "yolegroup.com": "Yole Group",
    "kipost.net": "KIPOST",
    "wccftech.com": "Wccftech",
    "techpowerup.com": "TechPowerUp",
    "eenewsembedded.com": "eeNews Embedded",
    "prnewswire.com": "PR Newswire",
    "asia.nikkei.com": "Nikkei Asia"
}

KOREA_TARGETS = {
    "thelec.kr": "TheElec",
    "etnews.com": "ETNews",
    "zdnet.co.kr": "ZDNet Korea",
    "hankyung.com": "Hankyung Insight"
}

ALL_TARGETS = {**GLOBAL_TARGETS, **KOREA_TARGETS}

# ë‚ ì”¨ ì½”ë“œ â†’ ì„¤ëª… ë§¤í•‘ (range ë°˜ë³µ ìƒì„± ì œê±°)
WEATHER_CODE_MAP = {
    0: "ë§‘ìŒ â˜€ï¸",
    1: "êµ¬ë¦„ ì¡°ê¸ˆ â›…", 2: "êµ¬ë¦„ ì¡°ê¸ˆ â›…", 3: "êµ¬ë¦„ ì¡°ê¸ˆ â›…",
    45: "ì•ˆê°œ ğŸŒ«ï¸", 48: "ì•ˆê°œ ğŸŒ«ï¸",
}
# 51~69: ë¹„, 70~79: ëˆˆ, 80+: í­ìš°/ë‡Œìš°
_RAIN_CODES = {c: "ë¹„ ğŸŒ§ï¸" for c in range(51, 70)}
_SNOW_CODES = {c: "ëˆˆ â„ï¸" for c in range(70, 80)}
WEATHER_CODE_MAP.update(_RAIN_CODES)
WEATHER_CODE_MAP.update(_SNOW_CODES)

MAX_ARTICLES = 10

# =========================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def get_pm_grade(value, thresholds, labels):
    """PM ìˆ˜ì¹˜ì— ë”°ë¥¸ ë“±ê¸‰ ë¬¸ìì—´ ë°˜í™˜"""
    if value is None:
        return "ì •ë³´ì—†ìŒ"
    for threshold, label in zip(thresholds, labels):
        if value <= threshold:
            return label
    return labels[-1]


def get_weather_info():
    """ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€(PM2.5/PM10) ì •ë³´ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤. (íŠœí”Œ ë°˜í™˜)"""
    LAT, LON = 36.99, 127.11  # ì•„ì‚°/ì²œì•ˆ ê¸°ì¤€

    # --- ë‚ ì”¨ ì •ë³´ ---
    try:
        weather_url = (
            f"https://api.open-meteo.com/v1/forecast"
            f"?latitude={LAT}&longitude={LON}"
            f"&current=temperature_2m,weather_code"
            f"&timezone=Asia%2FSeoul"
        )
        res = requests.get(weather_url, timeout=10).json()
        current = res.get('current', {})
        temp = current.get('temperature_2m', 0)
        code = current.get('weather_code', 0)

        weather_desc = WEATHER_CODE_MAP.get(code)
        if weather_desc is None:
            weather_desc = "í­ìš°/ë‡Œìš° â›ˆï¸" if code >= 80 else "ë§‘ìŒ â˜€ï¸"

        weather_str = f"{temp}Â°C, {weather_desc}"
    except (requests.RequestException, json.JSONDecodeError, KeyError) as e:
        log.warning(f"ë‚ ì”¨ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        weather_str = "ê¸°ì˜¨ ì •ë³´ ì—†ìŒ"

    # --- ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ---
    try:
        aq_url = (
            f"https://air-quality-api.open-meteo.com/v1/air-quality"
            f"?latitude={LAT}&longitude={LON}"
            f"&current=pm2_5,pm10"
            f"&timezone=Asia%2FSeoul"
        )
        aq_res = requests.get(aq_url, timeout=10).json()
        aq = aq_res.get('current', {})
        pm25 = aq.get('pm2_5')
        pm10 = aq.get('pm10')

        pm25_label = get_pm_grade(pm25, [15, 35, 75],
                                  ["ì¢‹ìŒ ğŸ’š", "ë³´í†µ ğŸ’›", "ë‚˜ì¨ ğŸŸ ", "ë§¤ìš°ë‚˜ì¨ ğŸ”´"])
        pm10_label = get_pm_grade(pm10, [30, 80, 150],
                                  ["ì¢‹ìŒ ğŸ’š", "ë³´í†µ ğŸ’›", "ë‚˜ì¨ ğŸŸ ", "ë§¤ìš°ë‚˜ì¨ ğŸ”´"])

        pm25_str = f"{pm25:.0f}ã/ã¥ {pm25_label}" if pm25 is not None else "ì •ë³´ì—†ìŒ"
        pm10_str = f"{pm10:.0f}ã/ã¥ {pm10_label}" if pm10 is not None else "ì •ë³´ì—†ìŒ"
        dust_str = f"ë¯¸ì„¸ë¨¼ì§€(PM10): {pm10_str} | ì´ˆë¯¸ì„¸ë¨¼ì§€(PM2.5): {pm25_str}"

    except (requests.RequestException, json.JSONDecodeError, KeyError) as e:
        log.warning(f"ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        dust_str = "ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ì—†ìŒ"

    return weather_str, dust_str


def get_new_kakao_token():
    url = "https://kauth.kakao.com/oauth/token"
    data = {
        "grant_type": "refresh_token",
        "client_id": KAKAO_REST_API_KEY,
        "client_secret": KAKAO_CLIENT_SECRET,
        "refresh_token": KAKAO_REFRESH_TOKEN
    }
    try:
        res = requests.post(url, data=data, timeout=10)
        res.raise_for_status()
        tokens = res.json()
        return tokens.get("access_token")
    except (requests.RequestException, json.JSONDecodeError) as e:
        log.error(f"ì¹´ì¹´ì˜¤ í† í° ê°±ì‹  ì‹¤íŒ¨: {e}")
        return None


def call_gemini(prompt, tag=""):
    """Gemini ëª¨ë¸ fallback í˜¸ì¶œ ê³µí†µ í•¨ìˆ˜. ì„±ê³µ ì‹œ í…ìŠ¤íŠ¸, ì‹¤íŒ¨ ì‹œ None."""
    for model in GEMINI_MODELS:
        try:
            resp = client.models.generate_content(model=model, contents=prompt)
            if resp.text:
                log.info(f"[{tag}] {model} ì„±ê³µ")
                return resp.text
        except Exception as e:
            log.warning(f"[{tag}] {model} ì‹¤íŒ¨: {e}")
            time.sleep(1)
    return None


# =========================================================
# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì²˜ë¦¬
# =========================================================
def fetch_news():
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    weekday = now_kst.weekday()

    if weekday == 6:  # ì¼ìš”ì¼
        log.info("ğŸ“… ì¼ìš”ì¼ì€ ë¦¬í¬íŠ¸ë¥¼ íœ´ê°„í•©ë‹ˆë‹¤.")
        return None

    is_monday = weekday == 0
    search_period = "7d" if is_monday else "2d"
    cutoff_hours = 168 if is_monday else 48
    cutoff_date = datetime.now(timezone.utc) - timedelta(hours=cutoff_hours)

    raw_articles = []

    def get_rss_entries(targets, region, lang):
        site_query = " OR ".join(f"site:{d}" for d in targets)
        kw_query = " OR ".join(KEYWORDS)
        final_query = f"({site_query}) AND ({kw_query})"
        encoded_query = urllib.parse.quote(final_query)
        url = (
            f"https://news.google.com/rss/search?q={encoded_query}"
            f"+when:{search_period}&hl={lang}&gl={region}&ceid={region}:{lang}"
        )
        try:
            feed = feedparser.parse(url)
            return feed.entries
        except Exception as e:
            log.warning(f"RSS íŒŒì‹± ì‹¤íŒ¨ ({region}): {e}")
            return []

    log.info(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ê¸°ê°„: {search_period})")
    raw_articles.extend(get_rss_entries(GLOBAL_TARGETS, "US", "en-US"))
    raw_articles.extend(get_rss_entries(KOREA_TARGETS, "KR", "ko"))

    valid_articles = []
    seen_links = set()

    for e in raw_articles:
        link = getattr(e, 'link', None)
        if not link or link in seen_links:
            continue

        # ë‚ ì§œ í•„í„°ë§
        published = getattr(e, 'published', None)
        if not published:
            continue
        try:
            pub_date = date_parser.parse(published)
            if pub_date.tzinfo is None:
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            if pub_date < cutoff_date:
                continue
        except (ValueError, OverflowError):
            continue

        # Google News URL ë””ì½”ë”©
        try:
            decoded_res = gnewsdecoder(link)
            if isinstance(decoded_res, dict):
                original_url = decoded_res.get('decoded_url', link)
            else:
                original_url = decoded_res or link
        except Exception:
            original_url = link

        original_url = str(original_url)
        domain = urlparse(original_url).netloc.replace("www.", "")

        source_name = "News"
        for t_domain, t_name in ALL_TARGETS.items():
            if t_domain in domain:
                source_name = t_name
                break

        e['display_source'] = source_name
        e['parsed_date'] = pub_date
        e['clean_url'] = original_url
        valid_articles.append(e)
        seen_links.add(link)

    log.info(f"ğŸ“° ìœ íš¨ ê¸°ì‚¬ ìˆ˜ì§‘: {len(valid_articles)}ê°œ")

    if not valid_articles:
        return None

    # â”€â”€ ì†ŒìŠ¤ë³„ë¡œ ë¬¶ê¸° â”€â”€
    buckets = defaultdict(list)
    for e in valid_articles:
        buckets[e['display_source']].append(e)

    # ê° ì†ŒìŠ¤ ë‚´ ìµœì‹ ìˆœ ì •ë ¬
    for src in buckets:
        buckets[src].sort(key=lambda x: x['parsed_date'], reverse=True)

    # â”€â”€ ë¼ìš´ë“œ-ë¡œë¹ˆìœ¼ë¡œ ì†ŒìŠ¤ ë‹¤ì–‘ì„± ë³´ì¥í•˜ë©° ìµœëŒ€ Nê°œ ì„ íƒ â”€â”€
    final_selection = []
    while len(final_selection) < MAX_ARTICLES:
        active_sources = [s for s in buckets if buckets[s]]
        if not active_sources:
            break
        # ë§¤ ë¼ìš´ë“œë§ˆë‹¤ ë‚¨ì€ ì†ŒìŠ¤ë¥¼ ìˆœíšŒ
        for src in active_sources:
            if len(final_selection) >= MAX_ARTICLES:
                break
            final_selection.append(buckets[src].pop(0))

    final_selection.sort(key=lambda x: x['parsed_date'], reverse=True)
    log.info(f"âœ… ìµœì¢… ì„ ì • ê¸°ì‚¬: {len(final_selection)}ê°œ")

    formatted_text = []
    for i, e in enumerate(final_selection):
        item = (
            f"[{i+1}] Source: {e['display_source']}\n"
            f"Title: {e.title}\n"
            f"URL: {e['clean_url']}\n"
        )
        formatted_text.append(item)

    return "\n".join(formatted_text)


# =========================================================
# 4. ì½˜í…ì¸  ìƒì„± (Gemini)
# =========================================================
def generate_content(news_text):
    log.info("ğŸ¤– AI ì „ì²´ ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    today_date = now_kst.strftime("%Yë…„ %mì›” %dì¼")
    publisher = "ë°˜ë„ì²´ì¬ë£Œê°œë°œTFT ê¹€ë™íœ˜"

    article_count = news_text.count("[")
    article_count_str = f"ì •í™•íˆ {article_count}ê°œ" if article_count > 0 else "10ê°œ"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°˜ë„ì²´ ì†Œì¬ ê°œë°œ ì—”ì§€ë‹ˆì–´ì´ì ì‚°ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì €ì‘ê¶Œë²• ì¤€ìˆ˜ë¥¼ ìœ„í•´ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì¬ìƒì‚°í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    ì˜¤ì§ ê¸°ì‚¬ì˜ 'ì œëª©', 'ì¹´í…Œê³ ë¦¬(í‚¤ì›Œë“œ)', 'ì¶œì²˜'ë§Œ ì •ë¦¬í•˜ì—¬ ë…ìê°€ ì›ë¬¸ì„ ë°©ë¬¸í•˜ë„ë¡ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.

    [ì‘ì„± ê·œì¹™]
    1. ê¸°ì‚¬ ë‚´ìš© ìš”ì•½ ê¸ˆì§€ (ì œëª©ê³¼ ë§í¬ë§Œ ì œê³µ).
    2. Executive SummaryëŠ” ì „ì²´ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ë³´ê³  ëŠê»´ì§€ëŠ” 'ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í‚¤ì›Œë“œ ë° ë¶„ìœ„ê¸°'ë§Œ 3ì¤„ë¡œ ì‘ì„±.
    3. Packaging Material InsightëŠ” 'ë°˜ë„ì²´ í›„ê³µì • ì†Œì¬(EMC, Underfill, Paste, Film ë“±)' ê°œë°œì ê´€ì ì—ì„œ ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ë“¤ì´ ì†Œì¬ ê¸°ìˆ ì— ë¯¸ì¹  ì˜í–¥ì´ë‚˜ ì¤‘ìš”ì„±ì„ 1ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±.
    4. ğŸŒ Headlines & Links ì„¹ì…˜ì—ëŠ” [ë‰´ìŠ¤ ë°ì´í„°]ì— ìˆëŠ” ëª¨ë“  ê¸°ì‚¬ë¥¼ ë¹ ì§ì—†ì´ ë‚˜ì—´í•´ì•¼ í•©ë‹ˆë‹¤. ({article_count_str} ì „ë¶€ í¬í•¨, ë‹¨ í•˜ë‚˜ë„ ìƒëµ ê¸ˆì§€)

    [í•„ìˆ˜ í˜•ì‹ - ë§ˆí¬ë‹¤ìš´]
    ##### {today_date} | ë°œí–‰ì¸: {publisher}

    ğŸ’¡ **Today's Market Mood**
    (ì „ì²´ì ì¸ ì‹œì¥ ê¸°ìˆ  íŠ¸ë Œë“œë‚˜ ë¶„ìœ„ê¸°ë§Œ 3ì¤„ ì‘ì„± - ê°œë³„ ê¸°ì‚¬ ì–¸ê¸‰ ê¸ˆì§€)

    ğŸŒ **Headlines & Links**
    (ì•„ë˜ ë‰´ìŠ¤ ë°ì´í„°ì˜ ëª¨ë“  ê¸°ì‚¬ë¥¼ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ ë¹ ì§ì—†ì´ ì‘ì„± - ìƒëµ ì ˆëŒ€ ê¸ˆì§€)
    1. **[ê¸°ì‚¬ ì œëª© ê·¸ëŒ€ë¡œ ì‘ì„±]**
       - ğŸ·ï¸ íƒœê·¸: [ê´€ë ¨ ê¸°ìˆ /ê¸°ì—… íƒœê·¸]
       - ğŸ”— ì›ë¬¸: [[ì–¸ë¡ ì‚¬ëª…](URL)] (ë°˜ë“œì‹œ ì›ë¬¸ ë§í¬ ì ìš©)
    2. ...
    (ë°ì´í„°ì— ìˆëŠ” ëª¨ë“  ê¸°ì‚¬ ë²ˆí˜¸ê¹Œì§€ ë°˜ë³µ)

    ğŸ“š **Word of the Day**
    (ì œëª©ì— ë“±ì¥í•œ ê¸°ìˆ  ìš©ì–´ ì¤‘ 1ê°œ ì„ ì •í•˜ì—¬ 1ì¤„ ì •ì˜)

    ğŸ§ª **Packaging Material Insight**
    (ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ íë¦„ì´ ë°˜ë„ì²´ íŒ¨í‚¤ì§• ì†Œì¬ ê°œë°œì— ì£¼ëŠ” ì‹œì‚¬ì  1ë¬¸ì¥)

    (ì¤„ë°”ê¿ˆ)
    ---
    *ë³¸ ë¦¬í¬íŠ¸ëŠ” ë‰´ìŠ¤ ë§í¬ë¥¼ ëª¨ì•„ ì œê³µí•˜ë©°, ê¸°ì‚¬ì˜ ì €ì‘ê¶Œì€ ê° ì–¸ë¡ ì‚¬ì— ìˆìŠµë‹ˆë‹¤. ìƒì„¸ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.*
    â“’ 2026 {publisher}.

    [ë‰´ìŠ¤ ë°ì´í„°]:
    {news_text}
    """

    result = call_gemini(prompt, tag="ë¦¬í¬íŠ¸")
    return result or "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"


def generate_kakao_briefing(news_text, weather_str, dust_str):
    """ì¹´ì¹´ì˜¤í†¡ ë¸Œë¦¬í•‘ ìƒì„±. ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€ + í–‰ë³µ ë©˜íŠ¸ í¬í•¨."""
    log.info("ğŸ’¬ ì¹´ì¹´ì˜¤í†¡ ë¸Œë¦¬í•‘ ìƒì„± ì‹œë„...")
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    today_str = now_kst.strftime("%m-%d")

    article_count = news_text.count("[")
    article_count_str = str(article_count) if article_count > 0 else "10"

    prompt = f"""
    ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  í™œê¸°ì°¬ í…Œí¬ ë‰´ìŠ¤ ì•Œë¦¬ë¯¸ì…ë‹ˆë‹¤.
    ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•´ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸ë§Œ ì‘ì„±í•˜ì„¸ìš”.
    ê¸¸ì´ëŠ” ê³µë°± í¬í•¨ 900ì ì´ë‚´.

    [ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ë° ë¯¸ì„¸ë¨¼ì§€ ì •ë³´]
    - ë‚ ì”¨: {weather_str}
    - {dust_str}

    [í˜•ì‹ - ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ì„¸ìš”]

    (ì²« ì¤„) ğŸš€ ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í—¤ë“œë¼ì¸ ({today_str})
    (ë¹ˆ ì¤„)
    (ë‰´ìŠ¤ ë°ì´í„°ì— ìˆëŠ” ê¸°ì‚¬ ì œëª©ì„ {article_count_str}ê°œ ì „ë¶€ ë‚˜ì—´ - ìƒëµ ì—†ì´)
    1. (ì œëª©) - (ë§¤ì²´ëª…)
    2. (ì œëª©) - (ë§¤ì²´ëª…)
    ...
    {article_count_str}. (ì œëª©) - (ë§¤ì²´ëª…)

    ---
    (ë‚ ì”¨ ì´ëª¨ì§€ + ë‚ ì”¨ ì •ë³´ í•œ ì¤„ í‘œê¸° (ì˜ˆ: â˜€ï¸ ë§‘ìŒ, ê¸°ì˜¨ ë“± í¬í•¨))
    (ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ í•œ ì¤„ í‘œê¸° (PM10 ë“±ê¸‰ê³¼ PM2.5 ë“±ê¸‰ì„ ì´ëª¨ì§€ì™€ í•¨ê»˜))
    (ë¹ˆ ì¤„)
    (ë‚ ì”¨ì™€ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœì— ë§ëŠ” ë”°ëœ»í•˜ê³  í–‰ë³µì„ ë¹„ëŠ” ê¸°ë¶„ ì¢‹ì€ ì¸ì‚¬ë§ 1~2ë¬¸ì¥.)
    (ì˜ˆ: ë¯¸ì„¸ë¨¼ì§€ê°€ ì¢‹ì€ ë‚ ì´ë©´ "ì˜¤ëŠ˜ì€ ë°”ê¹¥ ê³µê¸°ë„ ë§‘ìœ¼ë‹ˆ ì ê¹ ì‚°ì±…ë„ ì–´ë–¨ê¹Œìš”? í™œê¸°ì°¬ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ˜Š")
    (ì˜ˆ: ë¯¸ì„¸ë¨¼ì§€ê°€ ë‚˜ìœ ë‚ ì´ë©´ "ì˜¤ëŠ˜ì€ ë§ˆìŠ¤í¬ ê¼­ ì±™ê¸°ì„¸ìš”! ê±´ê°•í•˜ê³  í–‰ë³µí•œ í•˜ë£¨ ë³´ë‚´ì‹œê¸¸ ë°”ëë‹ˆë‹¤ ğŸ’ª")
    ---
    ğŸ“Œ ì›ë¬¸ ë§í¬ëŠ” ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]:
    {news_text}
    """

    result = call_gemini(prompt, tag="ì¹´ì¹´ì˜¤ ë¸Œë¦¬í•‘")
    if result:
        return result

    # â”€â”€ Fallback: AI ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ì¡°í•© â”€â”€
    log.warning("AI ë¸Œë¦¬í•‘ ì „ì²´ ì‹¤íŒ¨ â†’ fallback ë©”ì‹œì§€ ìƒì„±")
    titles = [
        line.replace("Title:", "").strip()
        for line in news_text.split('\n')
        if line.strip().startswith("Title:")
    ]

    lines = [
        f"ğŸš€ ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í—¤ë“œë¼ì¸ ({today_str})",
        "",
        "(AI ì„œë¹„ìŠ¤ ì§€ì—°ìœ¼ë¡œ ì œëª©ë§Œ ì „ì†¡í•©ë‹ˆë‹¤)",
    ]
    for i, t in enumerate(titles[:MAX_ARTICLES]):
        lines.append(f"{i+1}. {t}")
    lines.append("")
    lines.append("---")
    lines.append(f"ğŸŒ¤ï¸ {weather_str}")
    lines.append(f"ğŸƒ {dust_str}")
    lines.append("")
    lines.append("ì˜¤ëŠ˜ë„ ê±´ê°•í•˜ê³  í™œê¸°ì°¨ê²Œ! ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš” ğŸ˜Š")
    lines.append("---")
    lines.append("ğŸ“Œ ìƒì„¸ ë‚´ìš©ì€ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    return "\n".join(lines)


# =========================================================
# 5. ìŠ¤íƒ€ì¼ ê°•ì œ ì˜¤ë²„ë¼ì´ë”© í•¨ìˆ˜ (GitHub Pages)
# =========================================================
def apply_custom_css():
    css_path = "assets/css"
    os.makedirs(css_path, exist_ok=True)

    css_content = """---
---
@import "minima";

.site-header,
header,
.site-title,
.project-name,
.page-header,
.site-nav,
a.site-title,
.site-header .wrapper {
    display: none !important;
    visibility: hidden !important;
    opacity: 0 !important;
    height: 0 !important;
    overflow: hidden !important;
    pointer-events: none !important;
    margin: 0 !important;
    padding: 0 !important;
}

body, .page-content, .markdown-body, main {
    margin-top: 0 !important;
    padding-top: 10px !important;
}

.wrapper {
    margin-top: 0 !important;
}
"""
    with open(f"{css_path}/style.scss", "w", encoding="utf-8") as f:
        f.write(css_content)
    log.info("âœ… style.scss ìƒì„± ì™„ë£Œ")


def create_config_file():
    config_content = """title: ""
description: ""
show_downloads: false
theme: minima
header_pages: []
"""
    with open("_config.yml", "w", encoding="utf-8") as f:
        f.write(config_content)
    log.info("âœ… _config.yml ìƒì„± ì™„ë£Œ")


def create_custom_layout():
    layout_path = "_layouts"
    os.makedirs(layout_path, exist_ok=True)

    layout_content = """<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>{{ page.title | default: site.title }}</title>
  <link rel="stylesheet" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">
</head>
<body>
  <main class="page-content" aria-label="Content">
    <div class="wrapper">
      {{ content }}
    </div>
  </main>
</body>
</html>
"""
    with open(f"{layout_path}/default.html", "w", encoding="utf-8") as f:
        f.write(layout_content)
    log.info("âœ… ì»¤ìŠ¤í…€ ë ˆì´ì•„ì›ƒ ìƒì„± ì™„ë£Œ")


# =========================================================
# 6. ì „ì†¡ ë° ì €ì¥
# =========================================================
def save_newsletter(content):
    KST = timezone(timedelta(hours=9))
    now = datetime.now(KST)
    date_str = now.strftime("%Y-%m-%d")

    report_title = "Semi-TFT Weekly News" if now.weekday() == 0 else "Semi-TFT Daily News"

    inline_css = """
<style>
.site-header, .site-title { display: none !important; }
</style>
"""
    front_matter = f"""---
layout: default
title: "{report_title} ({date_str})"
---
{inline_css}

# ğŸ“¦ {report_title}
"""
    final_content = front_matter + content

    folder = f"newsletter/{date_str}"
    os.makedirs(folder, exist_ok=True)

    with open(f"{folder}/index.md", "w", encoding="utf-8") as f:
        f.write(final_content)

    with open("index.md", "w", encoding="utf-8") as f:
        f.write(final_content)

    log.info(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {folder}/index.md")


def send_kakao_message(briefing_text, report_url):
    access_token = get_new_kakao_token()
    if not access_token:
        log.error("âŒ ì¹´ì¹´ì˜¤ í† í° ê°±ì‹  ì‹¤íŒ¨")
        return

    # í—¤ë” ì—†ì´ ë¸Œë¦¬í•‘(ğŸš€ í—¤ë“œë¼ì¸)ì´ ë°”ë¡œ ì²« ì¤„ì— í‘œì‹œ
    # TinyURL ì œê±° â†’ ì›ë³¸ URL ì§ì ‘ ì‚¬ìš© (Preview ëŒ€ê¸° í˜ì´ì§€ ì—†ìŒ)
    suffix = "\n...(ë”ë³´ê¸°)"
    MAX_LEN = 950
    max_body = MAX_LEN - len(suffix)

    if len(briefing_text) > max_body:
        final_text = briefing_text[:max_body] + suffix
    else:
        final_text = briefing_text

    template = {
        "object_type": "text",
        "text": final_text,
        "link": {"web_url": report_url, "mobile_web_url": report_url},
        "buttons": [
            {
                "title": "ğŸ“° ì „ì²´ ë¦¬í¬íŠ¸ ë³´ê¸°",
                "link": {"web_url": report_url, "mobile_web_url": report_url}
            }
        ]
    }

    url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    try:
        res = requests.post(url, headers=headers,
                            data={"template_object": json.dumps(template)},
                            timeout=10)
        if res.status_code == 200:
            log.info("âœ… ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì„±ê³µ")
        else:
            log.error(f"âŒ ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì‹¤íŒ¨ ({res.status_code}): {res.text}")
    except requests.RequestException as e:
        log.error(f"âŒ ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì—ëŸ¬: {e}")


def send_email(subject, body_md, to_email):
    if not GMAIL_USER or not GMAIL_APP_PASSWORD:
        log.warning("âš ï¸ ì´ë©”ì¼ ì„¤ì • ëˆ„ë½ìœ¼ë¡œ ì „ì†¡ ê±´ë„ˆëœ€")
        return

    # ë§ˆí¬ë‹¤ìš´ â†’ ê°„ë‹¨ HTML ë³€í™˜ (ì¤„ë°”ê¿ˆ + ê¸°ë³¸ ë˜í•‘)
    html_body = (
        "<html><body style='font-family:sans-serif; line-height:1.6;'>"
        + body_md.replace("\n", "<br>")
        + "</body></html>"
    )

    msg = MIMEMultipart("alternative")
    msg['From'] = GMAIL_USER
    msg['To'] = to_email
    msg['Subject'] = subject
    msg.attach(MIMEText(body_md, 'plain', 'utf-8'))   # í”Œë ˆì¸ í…ìŠ¤íŠ¸ fallback
    msg.attach(MIMEText(html_body, 'html', 'utf-8'))   # HTML ë³¸ë¬¸

    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465, timeout=15) as s:
            s.login(GMAIL_USER, GMAIL_APP_PASSWORD)
            s.send_message(msg)
        log.info("ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ")
    except Exception as e:
        log.error(f"âŒ ì´ë©”ì¼ ì‹¤íŒ¨: {e}")


# =========================================================
# 7. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# =========================================================
def main():
    log.info("ğŸš€ ë‰´ìŠ¤ íë ˆì´ì…˜ ê³µì • ì‹œì‘")

    # GitHub Pages ìŠ¤íƒ€ì¼ íŒŒì¼ ìƒì„±
    apply_custom_css()
    create_config_file()
    create_custom_layout()

    # ë‰´ìŠ¤ ìˆ˜ì§‘
    news_text = fetch_news()
    if not news_text:
        log.info("ë‰´ìŠ¤ ì—†ìŒ ë˜ëŠ” íœ´ê°„ì¼ â†’ ì¢…ë£Œ")
        return

    # AI ë¦¬í¬íŠ¸ ìƒì„±
    full_text = generate_content(news_text)
    if full_text == "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨":
        log.error("âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ - ì¢…ë£Œ")
        raise SystemExit(1)

    save_newsletter(full_text)

    KST = timezone(timedelta(hours=9))
    date_str = datetime.now(KST).strftime("%Y-%m-%d")
    web_url = "https://semiconductortft-bit.github.io/semi-daily-news/"

    # API Rate Limit ë³´í˜¸ ëŒ€ê¸°
    log.info("â˜• API ë³´í˜¸ ëŒ€ê¸° (60ì´ˆ)...")
    time.sleep(60)

    # ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ìˆ˜ì§‘
    weather_str, dust_str = get_weather_info()
    log.info(f"ğŸŒ¤ï¸ {weather_str} | {dust_str}")

    # ì¹´ì¹´ì˜¤í†¡ ì „ì†¡
    kakao_msg = generate_kakao_briefing(news_text, weather_str, dust_str)
    send_kakao_message(kakao_msg, web_url)

    # ì´ë©”ì¼ ì „ì†¡
    send_email(
        f"ğŸ“¦ [ë°˜ë„ì²´ ë‰´ìŠ¤] {date_str}",
        full_text,
        "keenhwi@gmail.com"
    )

    log.info("âœ… ëª¨ë“  ê³µì • ì™„ë£Œ")


if __name__ == "__main__":
    try:
        main()
    except SystemExit:
        raise
    except Exception as e:
        log.critical(f"âš ï¸ ì‹œìŠ¤í…œ ì¹˜ëª…ì  ì—ëŸ¬: {e}", exc_info=True)
        raise SystemExit(1)
