import os
import time
import requests
import json
import feedparser
import urllib.parse
import smtplib
from datetime import datetime, timedelta, timezone
from google import genai
from collections import defaultdict
from urllib.parse import urlparse
from dateutil import parser as date_parser
from googlenewsdecoder import gnewsdecoder
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# =========================================================
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# =========================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
KAKAO_REFRESH_TOKEN = os.getenv("KAKAO_REFRESH_TOKEN")
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY")
KAKAO_CLIENT_SECRET = os.getenv("KAKAO_CLIENT_SECRET")
GMAIL_USER = os.getenv("GMAIL_USER")
GMAIL_APP_PASSWORD = os.getenv("GMAIL_APP_PASSWORD")

client = genai.Client(api_key=GEMINI_API_KEY)

KEYWORDS = [
    'semiconductor', 'advanced packaging', 'hbm', 'tsmc', 'samsung', 'sk hynix', 
    'wafer', 'chiplet', 'interposer', 'Hybrid Bonding', 'CoWoS', 'FOWLP', 'intel',
    'Glass Substrate', 'TC-NCF', 'MUF', 'EMC', 'CXL', 'BSPDN', 'Silicon Photonics',
    'Logic Semiconductor', 'Foundry', 'Automotive Chip', 'NVIDIA', 'AMD'
]

GLOBAL_TARGETS = {
    "semiengineering.com": "Semiconductor Engineering",
    "3dincites.com": "3D InCites",
    "digitimes.com": "Digitimes",
    "eetimes.com": "EE Times",
    "trendforce.com": "TrendForce",
    "semiconductor-digest.com": "Semi Digest",
    "yolegroup.com": "Yole Group",
    "kipost.net": "KIPOST",
    "wccftech.com": "Wccftech",
    "techpowerup.com": "TechPowerUp",
    "eenewsembedded.com": "eeNews Embedded",
    "prnewswire.com": "PR Newswire",
    "asia.nikkei.com": "Nikkei Asia"
}

KOREA_TARGETS = {
    "thelec.kr": "TheElec",
    "etnews.com": "ETNews",
    "zdnet.co.kr": "ZDNet Korea",
    "hankyung.com": "Hankyung Insight"
}

# =========================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def parse_date(date_str):
    try:
        return date_parser.parse(date_str)
    except:
        return datetime.now()

def get_pm_grade(value, thresholds, labels):
    """PM ìˆ˜ì¹˜ì— ë”°ë¥¸ ë“±ê¸‰ ë¬¸ìì—´ ë°˜í™˜"""
    if value is None:
        return "ì •ë³´ì—†ìŒ"
    for threshold, label in zip(thresholds, labels):
        if value <= threshold:
            return label
    return labels[-1]

def get_weather_info():
    """ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€(PM2.5/PM10) ì •ë³´ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤. (íŠœí”Œ ë°˜í™˜)"""
    LAT, LON = 36.99, 127.11  # ì•„ì‚°/ì²œì•ˆ ê¸°ì¤€

    # --- ë‚ ì”¨ ì •ë³´ ---
    try:
        weather_url = (
            f"https://api.open-meteo.com/v1/forecast"
            f"?latitude={LAT}&longitude={LON}"
            f"&current=temperature_2m,weather_code"
            f"&timezone=Asia%2FSeoul"
        )
        res = requests.get(weather_url, timeout=5).json()
        current = res.get('current', {})
        temp = current.get('temperature_2m', 0)
        code = current.get('weather_code', 0)

        weather_desc = "ë§‘ìŒ â˜€ï¸"
        if code in [1, 2, 3]:    weather_desc = "êµ¬ë¦„ ì¡°ê¸ˆ â›…"
        elif code in [45, 48]:   weather_desc = "ì•ˆê°œ ğŸŒ«ï¸"
        elif code in range(51, 70): weather_desc = "ë¹„ ğŸŒ§ï¸"
        elif code in range(70, 80): weather_desc = "ëˆˆ â„ï¸"
        elif code >= 80:          weather_desc = "í­ìš°/ë‡Œìš° â›ˆï¸"

        weather_str = f"{temp}Â°C, {weather_desc}"
    except Exception:
        weather_str = "ê¸°ì˜¨ ì •ë³´ ì—†ìŒ"

    # --- ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ (Open-Meteo Air Quality API - ë¬´ë£Œ, í‚¤ ë¶ˆí•„ìš”) ---
    try:
        aq_url = (
            f"https://air-quality-api.open-meteo.com/v1/air-quality"
            f"?latitude={LAT}&longitude={LON}"
            f"&current=pm2_5,pm10"
            f"&timezone=Asia%2FSeoul"
        )
        aq_res = requests.get(aq_url, timeout=5).json()
        aq = aq_res.get('current', {})
        pm25 = aq.get('pm2_5')
        pm10 = aq.get('pm10')

        # í•œêµ­ í™˜ê²½ë¶€ ê¸°ì¤€ PM2.5
        pm25_label = get_pm_grade(
            pm25,
            [15, 35, 75],
            ["ì¢‹ìŒ ğŸ’š", "ë³´í†µ ğŸ’›", "ë‚˜ì¨ ğŸŸ ", "ë§¤ìš°ë‚˜ì¨ ğŸ”´"]
        )
        # í•œêµ­ í™˜ê²½ë¶€ ê¸°ì¤€ PM10
        pm10_label = get_pm_grade(
            pm10,
            [30, 80, 150],
            ["ì¢‹ìŒ ğŸ’š", "ë³´í†µ ğŸ’›", "ë‚˜ì¨ ğŸŸ ", "ë§¤ìš°ë‚˜ì¨ ğŸ”´"]
        )

        pm25_str = f"{pm25:.0f}ã/ã¥ {pm25_label}" if pm25 is not None else "ì •ë³´ì—†ìŒ"
        pm10_str = f"{pm10:.0f}ã/ã¥ {pm10_label}" if pm10 is not None else "ì •ë³´ì—†ìŒ"
        dust_str = f"ë¯¸ì„¸ë¨¼ì§€(PM10): {pm10_str} | ì´ˆë¯¸ì„¸ë¨¼ì§€(PM2.5): {pm25_str}"

    except Exception:
        dust_str = "ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ì—†ìŒ"

    return weather_str, dust_str

def get_new_kakao_token():
    url = "https://kauth.kakao.com/oauth/token"
    data = {
        "grant_type": "refresh_token",
        "client_id": KAKAO_REST_API_KEY,
        "client_secret": KAKAO_CLIENT_SECRET,
        "refresh_token": KAKAO_REFRESH_TOKEN
    }
    try:
        res = requests.post(url, data=data)
        tokens = res.json()
        return tokens.get("access_token")
    except:
        return None

# =========================================================
# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì²˜ë¦¬
# =========================================================
def fetch_news():
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    weekday = now_kst.weekday()

    if weekday == 6:
        print("ğŸ“… ì¼ìš”ì¼ì€ ë¦¬í¬íŠ¸ë¥¼ íœ´ê°„í•©ë‹ˆë‹¤.")
        return None

    search_period = "7d" if weekday == 0 else "2d"
    cutoff_hours = 168 if weekday == 0 else 48
    cutoff_date = datetime.now(timezone.utc) - timedelta(hours=cutoff_hours)

    all_targets = {**GLOBAL_TARGETS, **KOREA_TARGETS}
    raw_articles = []

    def get_rss_entries(targets, region, lang):
        site_query = " OR ".join([f"site:{d}" for d in targets.keys()])
        kw_query = " OR ".join(KEYWORDS)
        final_query = f"({site_query}) AND ({kw_query})"
        encoded_query = urllib.parse.quote(final_query)
        url = (
            f"https://news.google.com/rss/search?q={encoded_query}"
            f"+when:{search_period}&hl={lang}&gl={region}&ceid={region}:{lang}"
        )
        return feedparser.parse(url).entries

    print(f"ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ê¸°ê°„: {search_period})")
    raw_articles.extend(get_rss_entries(GLOBAL_TARGETS, "US", "en-US"))
    raw_articles.extend(get_rss_entries(KOREA_TARGETS, "KR", "ko"))

    valid_articles = []
    seen_links = set()

    for e in raw_articles:
        if e.link in seen_links:
            continue
        try:
            pub_date = date_parser.parse(e.published)
            if pub_date.tzinfo is None:
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            if pub_date < cutoff_date:
                continue
        except:
            continue

        try:
            decoded_res = gnewsdecoder(e.link)
            if isinstance(decoded_res, dict):
                original_url = decoded_res.get('decoded_url', e.link)
            else:
                original_url = decoded_res if decoded_res else e.link
        except:
            original_url = e.link

        original_url = str(original_url)
        domain = urlparse(original_url).netloc.replace("www.", "")
        source_name = "News"
        for t_domain, t_name in all_targets.items():
            if t_domain in domain:
                source_name = t_name
                break

        e['display_source'] = source_name
        e['parsed_date'] = pub_date
        e['clean_url'] = original_url
        valid_articles.append(e)
        seen_links.add(e.link)

    print(f"ğŸ“° ìœ íš¨ ê¸°ì‚¬ ìˆ˜ì§‘: {len(valid_articles)}ê°œ")

    # â”€â”€ ì†ŒìŠ¤ë³„ë¡œ ë¬¶ê¸° â”€â”€
    buckets = defaultdict(list)
    for e in valid_articles:
        buckets[e['display_source']].append(e)

    sources = list(buckets.keys())
    if not sources:
        return "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."

    # â”€â”€ ì†ŒìŠ¤ ë‹¤ì–‘ì„±ì„ ìœ ì§€í•˜ë©° ìµœëŒ€ 10ê°œ ì„ íƒ (ë¼ìš´ë“œ-ë¡œë¹ˆ) â”€â”€
    # ë²„ê·¸ ìˆ˜ì •: sources ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¹„ì–´ìˆëŠ” ì†ŒìŠ¤ë¥¼ ê±´ë„ˆë›°ë„ë¡ ê°œì„ 
    final_selection = []
    idx = 0
    while len(final_selection) < 10:
        # ë‚¨ì€ ê¸°ì‚¬ê°€ ìˆëŠ” ì†ŒìŠ¤ë§Œ ì¶”ë ¤ëƒ„
        active_sources = [s for s in sources if buckets[s]]
        if not active_sources:
            break
        src = active_sources[idx % len(active_sources)]
        final_selection.append(buckets[src].pop(0))
        idx += 1

    final_selection.sort(key=lambda x: x['parsed_date'], reverse=True)

    print(f"âœ… ìµœì¢… ì„ ì • ê¸°ì‚¬: {len(final_selection)}ê°œ")

    formatted_text = []
    for i, e in enumerate(final_selection):
        item = (
            f"[{i+1}] Source: {e['display_source']}\n"
            f"Title: {e.title}\n"
            f"URL: {e['clean_url']}\n"
        )
        formatted_text.append(item)

    return "\n".join(formatted_text)

# =========================================================
# 4. ì½˜í…ì¸  ìƒì„± (Gemini)
# =========================================================
def generate_content(news_text):
    print("ğŸ¤– AI ì „ì²´ ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘... (Safe Mode + Material Insight)")
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    today_date = now_kst.strftime("%Yë…„ %mì›” %dì¼")
    publisher = "ë°˜ë„ì²´ì¬ë£Œê°œë°œTFT ê¹€ë™íœ˜"

    report_title = "Semi-TFT Weekly News" if now_kst.weekday() == 0 else "Semi-TFT Daily News"

    # ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ íŒŒì•… (í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œ)
    article_count = news_text.count("[")
    article_count_str = f"ì •í™•íˆ {article_count}ê°œ" if article_count > 0 else "10ê°œ"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°˜ë„ì²´ ì†Œì¬ ê°œë°œ ì—”ì§€ë‹ˆì–´ì´ì ì‚°ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì €ì‘ê¶Œë²• ì¤€ìˆ˜ë¥¼ ìœ„í•´ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì¬ìƒì‚°í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    ì˜¤ì§ ê¸°ì‚¬ì˜ 'ì œëª©', 'ì¹´í…Œê³ ë¦¬(í‚¤ì›Œë“œ)', 'ì¶œì²˜'ë§Œ ì •ë¦¬í•˜ì—¬ ë…ìê°€ ì›ë¬¸ì„ ë°©ë¬¸í•˜ë„ë¡ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.

    [ì‘ì„± ê·œì¹™]
    1. ê¸°ì‚¬ ë‚´ìš© ìš”ì•½ ê¸ˆì§€ (ì œëª©ê³¼ ë§í¬ë§Œ ì œê³µ).
    2. Executive SummaryëŠ” ì „ì²´ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ë³´ê³  ëŠê»´ì§€ëŠ” 'ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í‚¤ì›Œë“œ ë° ë¶„ìœ„ê¸°'ë§Œ 3ì¤„ë¡œ ì‘ì„±.
    3. Packaging Material InsightëŠ” 'ë°˜ë„ì²´ í›„ê³µì • ì†Œì¬(EMC, Underfill, Paste, Film ë“±)' ê°œë°œì ê´€ì ì—ì„œ ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ë“¤ì´ ì†Œì¬ ê¸°ìˆ ì— ë¯¸ì¹  ì˜í–¥ì´ë‚˜ ì¤‘ìš”ì„±ì„ 1ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±.
    4. ğŸŒ Headlines & Links ì„¹ì…˜ì—ëŠ” [ë‰´ìŠ¤ ë°ì´í„°]ì— ìˆëŠ” ëª¨ë“  ê¸°ì‚¬ë¥¼ ë¹ ì§ì—†ì´ ë‚˜ì—´í•´ì•¼ í•©ë‹ˆë‹¤. ({article_count_str} ì „ë¶€ í¬í•¨, ë‹¨ í•˜ë‚˜ë„ ìƒëµ ê¸ˆì§€)

    [í•„ìˆ˜ í˜•ì‹ - ë§ˆí¬ë‹¤ìš´]
    ##### {today_date} | ë°œí–‰ì¸: {publisher}

    ğŸ’¡ **Today's Market Mood**
    (ì „ì²´ì ì¸ ì‹œì¥ ê¸°ìˆ  íŠ¸ë Œë“œë‚˜ ë¶„ìœ„ê¸°ë§Œ 3ì¤„ ì‘ì„± - ê°œë³„ ê¸°ì‚¬ ì–¸ê¸‰ ê¸ˆì§€)

    ğŸŒ **Headlines & Links**
    (ì•„ë˜ ë‰´ìŠ¤ ë°ì´í„°ì˜ ëª¨ë“  ê¸°ì‚¬ë¥¼ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ ë¹ ì§ì—†ì´ ì‘ì„± - ìƒëµ ì ˆëŒ€ ê¸ˆì§€)
    1. **[ê¸°ì‚¬ ì œëª© ê·¸ëŒ€ë¡œ ì‘ì„±]**
       - ğŸ·ï¸ íƒœê·¸: [ê´€ë ¨ ê¸°ìˆ /ê¸°ì—… íƒœê·¸]
       - ğŸ”— ì›ë¬¸: [[ì–¸ë¡ ì‚¬ëª…](URL)] (ë°˜ë“œì‹œ ì›ë¬¸ ë§í¬ ì ìš©)
    2. ...
    (ë°ì´í„°ì— ìˆëŠ” ëª¨ë“  ê¸°ì‚¬ ë²ˆí˜¸ê¹Œì§€ ë°˜ë³µ)

    ğŸ“š **Word of the Day**
    (ì œëª©ì— ë“±ì¥í•œ ê¸°ìˆ  ìš©ì–´ ì¤‘ 1ê°œ ì„ ì •í•˜ì—¬ 1ì¤„ ì •ì˜)

    ğŸ§ª **Packaging Material Insight**
    (ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ íë¦„ì´ ë°˜ë„ì²´ íŒ¨í‚¤ì§• ì†Œì¬ ê°œë°œì— ì£¼ëŠ” ì‹œì‚¬ì  1ë¬¸ì¥)

    (ì¤„ë°”ê¿ˆ)
    ---
    *ë³¸ ë¦¬í¬íŠ¸ëŠ” ë‰´ìŠ¤ ë§í¬ë¥¼ ëª¨ì•„ ì œê³µí•˜ë©°, ê¸°ì‚¬ì˜ ì €ì‘ê¶Œì€ ê° ì–¸ë¡ ì‚¬ì— ìˆìŠµë‹ˆë‹¤. ìƒì„¸ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì›ë¬¸ ë§í¬ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.*
    â“’ 2026 {publisher}.

    [ë‰´ìŠ¤ ë°ì´í„°]:
    {news_text}
    """

    models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"]
    for m in models:
        try:
            resp = client.models.generate_content(model=m, contents=prompt)
            if resp.text:
                return resp.text
        except:
            continue
    return "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"

def generate_kakao_briefing(news_text, weather_str, dust_str):
    """ì¹´ì¹´ì˜¤í†¡ ë¸Œë¦¬í•‘ ìƒì„±. ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€ + í–‰ë³µ ë©˜íŠ¸ í¬í•¨."""
    print("ğŸ’¬ ì¹´ì¹´ì˜¤í†¡ ë¸Œë¦¬í•‘ ìƒì„± ì‹œë„...")
    KST = timezone(timedelta(hours=9))
    now_kst = datetime.now(KST)
    today_str = now_kst.strftime("%m-%d")

    # ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ íŒŒì•…
    article_count = news_text.count("[")
    article_count_str = str(article_count) if article_count > 0 else "10"

    models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"]

    prompt = f"""
    ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  í™œê¸°ì°¬ í…Œí¬ ë‰´ìŠ¤ ì•Œë¦¬ë¯¸ì…ë‹ˆë‹¤.
    ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•´ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , í—¤ë“œë¼ì¸ ë¦¬ìŠ¤íŠ¸ë§Œ ì‘ì„±í•˜ì„¸ìš”.
    ê¸¸ì´ëŠ” ê³µë°± í¬í•¨ 900ì ì´ë‚´.

    [ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ë° ë¯¸ì„¸ë¨¼ì§€ ì •ë³´]
    - ë‚ ì”¨: {weather_str}
    - {dust_str}

    [í˜•ì‹ - ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ì„¸ìš”]

    (ì²« ì¤„) ë‚ ì”¨ ì´ëª¨ì§€ + ë‚ ì”¨ ì •ë³´ í•œ ì¤„ í‘œê¸° (ì˜ˆ: â˜€ï¸ ë§‘ìŒ, ê¸°ì˜¨ ë“± í¬í•¨)
    (ë‘˜ì§¸ ì¤„) ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ í•œ ì¤„ í‘œê¸° (PM10 ë“±ê¸‰ê³¼ PM2.5 ë“±ê¸‰ì„ ì´ëª¨ì§€ì™€ í•¨ê»˜)
    (ì…‹ì§¸ ì¤„) ë¹ˆ ì¤„
    (ë„·ì§¸ ì¤„) ë‚ ì”¨ì™€ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœì— ë§ëŠ” ë”°ëœ»í•˜ê³  í–‰ë³µì„ ë¹„ëŠ” ê¸°ë¶„ ì¢‹ì€ ì¸ì‚¬ë§ 1~2ë¬¸ì¥.
    (ì˜ˆ: ë¯¸ì„¸ë¨¼ì§€ê°€ ì¢‹ì€ ë‚ ì´ë©´ "ì˜¤ëŠ˜ì€ ë°”ê¹¥ ê³µê¸°ë„ ë§‘ìœ¼ë‹ˆ ì ê¹ ì‚°ì±…ë„ ì–´ë–¨ê¹Œìš”? í™œê¸°ì°¬ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ˜Š")
    (ì˜ˆ: ë¯¸ì„¸ë¨¼ì§€ê°€ ë‚˜ìœ ë‚ ì´ë©´ "ì˜¤ëŠ˜ì€ ë§ˆìŠ¤í¬ ê¼­ ì±™ê¸°ì„¸ìš”! ê±´ê°•í•˜ê³  í–‰ë³µí•œ í•˜ë£¨ ë³´ë‚´ì‹œê¸¸ ë°”ëë‹ˆë‹¤ ğŸ’ª")
    ---
    ğŸš€ ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í—¤ë“œë¼ì¸ ({today_str})

    (ë‰´ìŠ¤ ë°ì´í„°ì— ìˆëŠ” ê¸°ì‚¬ ì œëª©ì„ {article_count_str}ê°œ ì „ë¶€ ë‚˜ì—´ - ìƒëµ ì—†ì´)
    1. (ì œëª©) - (ë§¤ì²´ëª…)
    2. (ì œëª©) - (ë§¤ì²´ëª…)
    ...
    {article_count_str}. (ì œëª©) - (ë§¤ì²´ëª…)

    ---
    ğŸ“Œ ì›ë¬¸ ë§í¬ëŠ” ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.

    [ë‰´ìŠ¤ ë°ì´í„°]:
    {news_text}
    """

    for model_name in models:
        try:
            response = client.models.generate_content(model=model_name, contents=prompt)
            if response.text:
                return response.text
        except Exception:
            time.sleep(1)
            continue

    # â”€â”€ Fallback: AI ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ì¡°í•© â”€â”€
    titles = []
    for line in news_text.split('\n'):
        if line.startswith("Title:"):
            titles.append(line.replace("Title:", "").strip())

    fallback_msg = (
        f"ğŸŒ¤ï¸ {weather_str}\n"
        f"ğŸƒ {dust_str}\n\n"
        f"ì˜¤ëŠ˜ë„ ê±´ê°•í•˜ê³  í™œê¸°ì°¨ê²Œ! ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš” ğŸ˜Š\n"
        f"---\n"
        f"ğŸš€ ì˜¤ëŠ˜ì˜ ë°˜ë„ì²´ í—¤ë“œë¼ì¸ ({today_str})\n\n"
        f"(AI ì„œë¹„ìŠ¤ ì§€ì—°ìœ¼ë¡œ ì œëª©ë§Œ ì „ì†¡í•©ë‹ˆë‹¤)\n"
    )
    for i, t in enumerate(titles[:10]):
        fallback_msg += f"{i+1}. {t}\n"
    fallback_msg += "\n---\nğŸ“Œ ìƒì„¸ ë‚´ìš©ì€ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    return fallback_msg

# =========================================================
# 5. ìŠ¤íƒ€ì¼ ê°•ì œ ì˜¤ë²„ë¼ì´ë”© í•¨ìˆ˜ (í•µì‹¬)
# =========================================================
def apply_custom_css():
    css_path = "assets/css"
    if not os.path.exists(css_path):
        os.makedirs(css_path, exist_ok=True)
    
    css_content = """---
---
@import "minima";

.site-header, 
header, 
.site-title, 
.project-name,
.page-header,
.site-nav,
a.site-title,
.site-header .wrapper { 
    display: none !important; 
    visibility: hidden !important;
    opacity: 0 !important;
    height: 0 !important;
    overflow: hidden !important;
    pointer-events: none !important;
    margin: 0 !important;
    padding: 0 !important;
}

body, .page-content, .markdown-body, main {
    margin-top: 0 !important;
    padding-top: 10px !important;
}

.wrapper {
    margin-top: 0 !important;
}
"""
    with open(f"{css_path}/style.scss", "w", encoding="utf-8") as f:
        f.write(css_content)
    print("âœ… ê°•ë ¥í•œ ìŠ¤íƒ€ì¼ ì œê±° íŒŒì¼(assets/css/style.scss) ìƒì„± ì™„ë£Œ")

def create_config_file():
    config_content = """title: ""
description: ""
show_downloads: false
theme: minima
header_pages: []
"""
    with open("_config.yml", "w", encoding="utf-8") as f:
        f.write(config_content)
    print("âœ… _config.yml ìƒì„± ì™„ë£Œ (ì‚¬ì´íŠ¸ ì œëª© ì œê±°)")

def create_custom_layout():
    layout_path = "_layouts"
    if not os.path.exists(layout_path):
        os.makedirs(layout_path, exist_ok=True)
    
    layout_content = """<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>{{ page.title | default: site.title }}</title>
  <link rel="stylesheet" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">
</head>
<body>
  <main class="page-content" aria-label="Content">
    <div class="wrapper">
      {{ content }}
    </div>
  </main>
</body>
</html>
"""
    with open(f"{layout_path}/default.html", "w", encoding="utf-8") as f:
        f.write(layout_content)
    print("âœ… ì»¤ìŠ¤í…€ ë ˆì´ì•„ì›ƒ(_layouts/default.html) ìƒì„± ì™„ë£Œ")

# =========================================================
# 6. ì „ì†¡ ë° ì €ì¥
# =========================================================
def save_newsletter(content):
    KST = timezone(timedelta(hours=9))
    now = datetime.now(KST)
    date_str = now.strftime("%Y-%m-%d")
    
    report_title = "Semi-TFT Weekly News" if now.weekday() == 0 else "Semi-TFT Daily News"
    
    inline_css = """
<style>
.site-header, .site-title { display: none !important; }
</style>
"""
    front_matter = f"""---
layout: default
title: "{report_title} ({date_str})"
---
{inline_css}

# ğŸ“¦ {report_title}
"""
    final_content = front_matter + content

    folder = f"newsletter/{date_str}"
    if not os.path.exists(folder):
        os.makedirs(folder, exist_ok=True)

    with open(f"{folder}/index.md", "w", encoding="utf-8") as f:
        f.write(final_content)

    with open("index.md", "w", encoding="utf-8") as f:
        f.write(final_content)

    print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {folder}/index.md")

def send_kakao_message(briefing_text, report_url):
    access_token = get_new_kakao_token()
    if not access_token:
        print("âŒ ì¹´ì¹´ì˜¤ í† í° ê°±ì‹  ì‹¤íŒ¨")
        return

    url = "https://kapi.kakao.com/v2/api/talk/memo/default/send"
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    try:
        short_url = shorten_url(report_url)
    except:
        short_url = report_url

    header = "ğŸ“¦ ê¹€ë™íœ˜ì…ë‹ˆë‹¤."
    footer = f"\n\nğŸ”— {short_url}"
    suffix = "\n...(ë”ë³´ê¸°)"

    MAX_LEN = 950
    fixed_len = len(header) + len("\n\n") + len(footer)
    max_body = MAX_LEN - fixed_len - len(suffix)

    if len(briefing_text) > max_body:
        safe_text = briefing_text[:max_body] + suffix
    else:
        safe_text = briefing_text

    final_text = f"{header}\n\n{safe_text}{footer}"

    template = {
        "object_type": "text",
        "text": final_text,
        "link": {"web_url": report_url, "mobile_web_url": report_url},
        "buttons": [
            {
                "title": "ğŸ“° ì „ì²´ ë¦¬í¬íŠ¸ ë³´ê¸°",
                "link": {"web_url": report_url, "mobile_web_url": report_url}
            }
        ]
    }

    try:
        res = requests.post(url, headers=headers, data={"template_object": json.dumps(template)})
        if res.status_code == 200:
            print("âœ… ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì„±ê³µ")
        else:
            print(f"âŒ ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì‹¤íŒ¨: {res.text}")
    except Exception as e:
        print(f"âŒ ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì—ëŸ¬: {e}")

def shorten_url(long_url):
    try:
        api_url = f"https://tinyurl.com/api-create.php?url={urllib.parse.quote(long_url)}"
        response = requests.get(api_url, timeout=5)
        if response.status_code == 200:
            return response.text
    except:
        pass
    return long_url

def send_email(subject, body, to_email):
    if not GMAIL_USER or not GMAIL_APP_PASSWORD:
        print("âš ï¸ ì´ë©”ì¼ ì„¤ì • ëˆ„ë½ìœ¼ë¡œ ì „ì†¡ ê±´ë„ˆëœ€")
        return

    msg = MIMEMultipart()
    msg['From'] = GMAIL_USER
    msg['To'] = to_email
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'html'))
    try:
        s = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        s.login(GMAIL_USER, GMAIL_APP_PASSWORD)
        s.send_message(msg)
        s.quit()
        print("ğŸ“§ ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ì‹¤íŒ¨: {e}")

# =========================================================
# 7. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# =========================================================
if __name__ == "__main__":
    try:
        print("ğŸš€ ë‰´ìŠ¤ íë ˆì´ì…˜ ê³µì • ì‹œì‘")

        apply_custom_css()
        create_config_file()
        create_custom_layout()

        raw_data = fetch_news()

        if not raw_data:
            print("ë‰´ìŠ¤ ì—†ìŒ ì¢…ë£Œ")
            exit(0)

        if isinstance(raw_data, list):
            news_text = "\n".join([f"Title: {e.title}" for e in raw_data])
        else:
            news_text = raw_data

        # AI ë¦¬í¬íŠ¸ ìƒì„±
        full_text = generate_content(news_text)

        if not full_text or full_text == "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨":
            print("âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ - ì¢…ë£Œ")
            exit(1)

        save_newsletter(full_text)

        KST = timezone(timedelta(hours=9))
        date_str = datetime.now(KST).strftime("%Y-%m-%d")
        web_url = "https://semiconductortft-bit.github.io/semi-daily-news/"

        print("â˜• API ë³´í˜¸ ëŒ€ê¸° (60ì´ˆ)...")
        time.sleep(60)

        # â”€â”€ ë‚ ì”¨ + ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ìˆ˜ì§‘ (íŠœí”Œ ì–¸íŒ¨í‚¹) â”€â”€
        weather_str, dust_str = get_weather_info()
        print(f"ğŸŒ¤ï¸ {weather_str} | {dust_str}")

        kakao_msg = generate_kakao_briefing(news_text, weather_str, dust_str)
        send_kakao_message(kakao_msg, web_url)

        send_email(f"ğŸ“¦ [ë°˜ë„ì²´ ë‰´ìŠ¤] {date_str}", full_text.replace("\n", "<br>"), "keenhwi@gmail.com")

        print("âœ… ëª¨ë“  ê³µì • ì™„ë£Œ")

    except Exception as e:
        print(f"âš ï¸ ì‹œìŠ¤í…œ ì¹˜ëª…ì  ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
